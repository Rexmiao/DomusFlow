{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1ZC7is2fKKNieb90W3BC669pu9xJSMfBS","authorship_tag":"ABX9TyOUGM/B4lVg0Lp0tY06IGqC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install openai==0.28"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"51Xbzd47AHlX","executionInfo":{"status":"ok","timestamp":1708201569914,"user_tz":300,"elapsed":11808,"user":{"displayName":"Rongqian Chen","userId":"06966833615054754052"}},"outputId":"c7852f5e-60f1-4950-cb0a-d77608e3d737"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n","Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.2)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n"]}]},{"cell_type":"markdown","source":["Separate the abstract into several scenes by chatGPT"],"metadata":{"id":"zFnVROh0skV_"}},{"cell_type":"code","source":["import openai\n","\n","openai.api_key = \"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\"\n","with open(\"Abstract.txt\", 'r') as file:\n","    file_contents = file.read()\n","# messages = [ {\"role\": \"system\", \"content\": \"You are a intelligent assistant.\"} ]\n","message = [\"Following is an abstract, now separate the abstract into five scenes for video animation, each scene has a separate paragraph:\\n\"]\n","message = [message[0]+ file_contents]\n","print(message)\n","messages = []\n","\n","if message:\n","  messages.append(\n","    {\"role\": \"user\", \"content\": message[0]},\n","  )\n","  chat = openai.ChatCompletion.create(\n","    model=\"gpt-4\", messages=messages\n","  )\n","  print(chat.usage.total_tokens)\n","\n","reply = chat.choices[0].message.content\n","print(f\"ChatGPT: {reply}\")\n","messages.append({\"role\": \"assistant\", \"content\": reply})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nc9_2iSPsjSo","executionInfo":{"status":"ok","timestamp":1708202002277,"user_tz":300,"elapsed":9458,"user":{"displayName":"Rongqian Chen","userId":"06966833615054754052"}},"outputId":"7004afab-af7d-46c9-8249-ebf612e32295"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["['Following is an abstract, now separate the abstract into five scenes for video animation, each scene has a separate paragraph:\\nIn 1957, Eugene Smith walked away from his longtime job at\\xa0Life\\xa0and the home he shared with his wife and four children to move into a dilapidated, five-story loft building at 821 Sixth Avenue in New York City’s wholesale flower district. The loft was the late-night haunt of musicians, including some of the biggest names in jazz—Charles Mingus, Zoot Sims, Bill Evans, and Thelonious Monk among them. Here, from 1957 to 1965, he made nearly 40,000 photographs and approximately 4,000 hours of recordings of musicians. Smith found solace in the chaotic, somnambulistic world of the loft and its artists, and he turned his documentary impulses away from work on his major Pittsburg photo essay and toward his new surroundings.']\n","523\n","ChatGPT: Scene 1:\n","The year is 1957. The setting is an office space at Life magazine. Eugene Smith is packing his belongings, as his colleagues watch aghast. We see the mixture of fear and excitement in his eyes as he bids goodbye to his longtime job.\n","\n","Scene 2:\n","The view shifts to a quintessential 1950s suburban home. We see Eugene's wife and four children waving him goodbye, a hint of sadness in their eyes. The car pulls away from the driveway, leaving behind the warmth of a family home.\n","\n","Scene 3:\n","The New York's wholesale flower district appears, bustling with people and colors. We zoom in on a dilapidated, five-story loft building: number 821, Sixth Avenue. We see Smith, bags in hand, stepping into his new home – a stark contrast to his previous residence.\n","\n","Scene 4:\n","As the sun sets, the loft comes alive. There is the sound of jazz music wafting through the floorboards. We see Charles Mingus, Zoot Sims, Bill Evans, and Thelonious Monk among the musicians who used this space as a late-night haunt. Eugene Smith is in the middle of it all, just as lost in the music and the moment.\n","\n","Scene 5:\n","The focus returns to Smith, behind his camera, capturing images of the musicians and artists in the loft. He is in his element, engrossed in documenting their energy and camaraderie. The scene closes with a montage of photos that Smith took during his time in the loft, symbolizing his journey from 1957 to 1965.\n"]}]},{"cell_type":"markdown","source":["The following code is use for image generation."],"metadata":{"id":"kzAQC_AWAYPS"}},{"cell_type":"code","source":["import requests\n","import os\n","import base64\n","from PIL import Image\n","from io import BytesIO\n","\n","# Replace the empty string with your model id below\n","video_model_id = \"7qkldg93\"\n","image_model_id = \"8w67oe0q\"\n","baseten_api_key = \"fXFV4Kc3.pGZG3bywECzJFnbgreASZVXeiOHoGVdV\"\n","BASE64_PREAMBLE = \"data:image/png;base64,\"\n","file_path = \"description5.txt\"\n","\n","# Function used to convert a base64 string to a PIL image\n","def b64_to_pil(b64_str):\n","    return Image.open(BytesIO(base64.b64decode(b64_str.replace(BASE64_PREAMBLE, \"\"))))\n","\n","with open(file_path, 'r') as file:\n","    file_contents = file.read()\n","\n","data = {\n","  \"prompt\": file_contents\n","}\n","# Call model endpoint\n","res = requests.post(\n","    f\"https://model-{image_model_id}.api.baseten.co/production/predict\",\n","    headers={\"Authorization\": f\"Api-Key {baseten_api_key}\"},\n","    json=data\n",")\n","\n","# Get output image\n","res = res.json()\n","output = res.get(\"data\")\n","\n","# Convert the base64 model output to an image\n","img = b64_to_pil(output)\n","img.save(\"output_image.png\")\n","os.system(\"open output_image.png\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z36MxY-OAGiZ","executionInfo":{"status":"ok","timestamp":1708204080209,"user_tz":300,"elapsed":8614,"user":{"displayName":"Rongqian Chen","userId":"06966833615054754052"}},"outputId":"ee3fd0cc-09bc-4768-f6e3-2932c7fd2e29"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["768"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["The following code is for generating videos from images in the folder."],"metadata":{"id":"sDlvGBNnApsS"}},{"cell_type":"code","source":["def base64_to_mp4(base64_string, output_file_path):\n","    binary_data = base64.b64decode(base64_string)\n","    with open(output_file_path, \"wb\") as output_file:\n","        output_file.write(binary_data)\n","\n","def mp4_to_base64(file_path: str):\n","    with open(file_path, \"rb\") as mp4_file:\n","        binary_data = mp4_file.read()\n","        base64_data = base64.b64encode(binary_data)\n","        base64_string = base64_data.decode(\"utf-8\")\n","    return base64_string\n","\n","def image_to_base64(image_path):\n","    with open(image_path, \"rb\") as image_file:\n","        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n","    return encoded_string\n","\n","data = {\n","  \"image\": image_to_base64(\"./output_image5.png\"),\n","  \"num_frames\": 50,\n","  \"fps\": 25,\n","  \"decoding_t\": 10,\n","  \"duration\": 2\n","}\n","\n","# Call model endpoint\n","res = requests.post(\n","    f\"https://model-{video_model_id}.api.baseten.co/production/predict\",\n","    headers={\"Authorization\": f\"Api-Key cCa3xKMc.wFezUNugVQGX9vDfsPUqpbxcEc05f9LJ\"},\n","    json=data\n",")\n","\n","# Get the output of the model\n","res = res.json()\n","base64_output = res.get(\"output\")\n","\n","# Convert the base64 output to an mp4 video\n","base64_to_mp4(base64_output, \"video5.mp4\")"],"metadata":{"id":"13RtUW0TASnj","executionInfo":{"status":"ok","timestamp":1708204175828,"user_tz":300,"elapsed":74516,"user":{"displayName":"Rongqian Chen","userId":"06966833615054754052"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["analyze the mood and add background music:"],"metadata":{"id":"0ZDMa1PKi54z"}},{"cell_type":"code","source":["!pip install textblob\n","!python -m textblob.download_corpora\n","!pip install nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KTvC42jurn_e","executionInfo":{"status":"ok","timestamp":1708200552974,"user_tz":300,"elapsed":17814,"user":{"displayName":"Rongqian Chen","userId":"06966833615054754052"}},"outputId":"ccddadae-8e86-4ca3-e715-a50b46c7fe8d"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n","Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.2)\n","[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/brown.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package conll2000 to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/conll2000.zip.\n","[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/movie_reviews.zip.\n","Finished.\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"]}]},{"cell_type":"code","source":["from textblob import TextBlob\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from collections import Counter\n","\n","def extract_music_keywords(text):\n","    # Tokenize the text\n","    blob = TextBlob(text)\n","    words = [word.lower() for word in blob.words if word.isalpha()]\n","\n","    # Remove stopwords\n","    stop_words = set(stopwords.words(\"english\"))\n","    filtered_words = [word for word in words if word not in stop_words]\n","\n","    # Extract keywords\n","    keywords = Counter(filtered_words)\n","\n","    # Define music-related keywords based on scene context\n","    music_keywords = {\n","        'upbeat': ['cheerful', 'smile', 'joyful', 'energetic'],\n","        'relaxing': ['calm', 'comfort', 'peaceful', 'serene'],\n","        'melancholic': ['sad', 'melancholy', 'wistful', 'nostalgic'],\n","        'intense': ['tense', 'dramatic', 'powerful', 'emotional']\n","    }\n","\n","    # Find the most frequent keywords that match the music-related context\n","    matched_keywords = Counter()\n","    for mood, mood_keywords in music_keywords.items():\n","        matched_keywords[mood] += sum(keywords[key] for key in keywords if key in mood_keywords)\n","\n","    # Return the most frequent mood keywords\n","    top_moods = matched_keywords.most_common(3)\n","\n","    return [mood for mood, _ in top_moods]\n","\n","# # Example text input\n","# text = \"\"\"\n","# The story of a father who neglects his responsibilities as the head of the family, a mother who thinks finding the bridegrooms for their daughters is the only goal in her life. Pride and Prejudice written by Jane Austen is narrated in the point of view of the key character of Elizabeth Bennet, the second of the five daughters. Elizabeth’s courtship with Fitzwilliam Darcy, a wealthy and eligible bachelor who owns a family estate is narrated by the author in a sequence of incidents which deal with 19th century England social issues of manners, morality and education.\"\"\"\n","\n","# Get music-related keywords\n","music_keywords = extract_music_keywords(file_contents)\n","print(\"Music-related keywords:\", music_keywords)\n","\n","length = 10  # Length of music clip in seconds\n","keyword = music_keywords\n","\n","resp = requests.post(\n","    \"https://model-232pg60q.api.baseten.co/production/predict\",\n","    headers={\"Authorization\": \"Api-Key cdwwufG4.wYPONrLlil3QcVDmHbdz2JSRJcJ2YLnU\"},\n","    json={'prompts': keyword, 'duration': length},\n",")\n","\n","print(resp.json())\n","\n","# Convert the base64 output to an audio file\n","res = resp.json()\n","output = res.get(\"data\")\n","for idx, clip in enumerate(output):\n","    with open(f\"music{idx}.wav\", \"wb\") as f:\n","        f.write(base64.b64decode(clip))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1od4kONkQpcioycNilW3DyXW16_UqvTjc"},"id":"RzzrwoMZi2Zh","executionInfo":{"status":"ok","timestamp":1708204247163,"user_tz":300,"elapsed":70943,"user":{"displayName":"Rongqian Chen","userId":"06966833615054754052"}},"outputId":"b7401885-4632-433b-82a4-ce88da15d6a5"},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["Concatenate 5 videos and attach the music to the video"],"metadata":{"id":"k-AKAmt02GqP"}},{"cell_type":"code","source":["from moviepy.editor import VideoFileClip, concatenate_videoclips, AudioFileClip\n","\n","# Paths to your video files\n","video_files = [\n","    'video1.mp4',\n","    'video2.mp4',\n","    'video3.mp4',\n","    'video4.mp4',\n","    'video5.mp4'\n","]\n","\n","# Load the video clips\n","clips = [VideoFileClip(video) for video in video_files]\n","\n","# Concatenate the video clips\n","concat_clip = concatenate_videoclips(clips, method=\"compose\")\n","\n","# Path to your audio file\n","audio_path = 'music0.wav'\n","\n","# Load the audio file\n","audio_clip = AudioFileClip(audio_path)\n","\n","# Increase the volume of the audio. Here, the volume is doubled.\n","audio_clip = audio_clip.volumex(3.0)\n","\n","# Set the audio of the concatenated clip\n","concat_clip = concat_clip.set_audio(audio_clip)\n","\n","# Output file path\n","output_path = 'output_video3.mp4'\n","\n","# Write the result to a file\n","concat_clip.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\")\n","\n","# Remember to close all the clips to free up system resources\n","for clip in clips:\n","    clip.close()\n","audio_clip.close()\n","concat_clip.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"soUkdjEb2Bgf","executionInfo":{"status":"ok","timestamp":1708204599663,"user_tz":300,"elapsed":11974,"user":{"displayName":"Rongqian Chen","userId":"06966833615054754052"}},"outputId":"5316d5cf-8f92-499e-ed9e-ef4e8796eb72"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["t:   3%|▎         | 2/70 [05:25<3:04:29, 162.79s/it, now=None]"]},{"output_type":"stream","name":"stdout","text":["Moviepy - Building video output_video3.mp4.\n","MoviePy - Writing audio in output_video3TEMP_MPY_wvf_snd.mp4\n"]},{"output_type":"stream","name":"stderr","text":["\n","chunk:   0%|          | 0/221 [00:00<?, ?it/s, now=None]\u001b[A\n","chunk:  37%|███▋      | 82/221 [00:00<00:00, 806.50it/s, now=None]\u001b[A\n","chunk:  74%|███████▍  | 163/221 [00:00<00:00, 707.28it/s, now=None]\u001b[A\n","t:   3%|▎         | 2/70 [05:25<3:04:41, 162.96s/it, now=None]"]},{"output_type":"stream","name":"stdout","text":["MoviePy - Done.\n","Moviepy - Writing video output_video3.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","t:   0%|          | 0/70 [00:00<?, ?it/s, now=None]\u001b[A\n","t:   7%|▋         | 5/70 [00:00<00:01, 42.01it/s, now=None]\u001b[A\n","t:  14%|█▍        | 10/70 [00:00<00:01, 36.90it/s, now=None]\u001b[A\n","t:  20%|██        | 14/70 [00:00<00:01, 35.94it/s, now=None]\u001b[A\n","t:  26%|██▌       | 18/70 [00:00<00:01, 35.32it/s, now=None]\u001b[A\n","t:  31%|███▏      | 22/70 [00:00<00:01, 35.96it/s, now=None]\u001b[A\n","t:  39%|███▊      | 27/70 [00:00<00:01, 38.11it/s, now=None]\u001b[A\n","t:  46%|████▌     | 32/70 [00:00<00:00, 38.92it/s, now=None]\u001b[A\n","t:  51%|█████▏    | 36/70 [00:00<00:00, 38.33it/s, now=None]\u001b[A\n","t:  57%|█████▋    | 40/70 [00:01<00:00, 37.60it/s, now=None]\u001b[A\n","t:  64%|██████▍   | 45/70 [00:01<00:00, 39.40it/s, now=None]\u001b[A\n","t:  70%|███████   | 49/70 [00:01<00:00, 37.04it/s, now=None]\u001b[A\n","t:  76%|███████▌  | 53/70 [00:01<00:00, 36.39it/s, now=None]\u001b[A\n","t:  81%|████████▏ | 57/70 [00:01<00:00, 22.28it/s, now=None]\u001b[A\n","t:  86%|████████▌ | 60/70 [00:02<00:00, 16.44it/s, now=None]\u001b[A\n","t:  90%|█████████ | 63/70 [00:02<00:00, 12.89it/s, now=None]\u001b[A\n","t:  93%|█████████▎| 65/70 [00:02<00:00, 11.77it/s, now=None]\u001b[A\n","t:  96%|█████████▌| 67/70 [00:02<00:00, 10.37it/s, now=None]\u001b[A\n","t:  99%|█████████▊| 69/70 [00:03<00:00,  9.60it/s, now=None]\u001b[A\n","t:   3%|▎         | 2/70 [05:37<3:11:01, 168.56s/it, now=None]"]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready output_video3.mp4\n"]}]}]}